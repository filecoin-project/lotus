//go:generate go run ./gen

package dagspliter

import (
	"bytes"
	"context"
	"fmt"
	"io/ioutil"
	"os"
	"path/filepath"

	"github.com/docker/go-units"
	"github.com/filecoin-project/lotus/lib/ipfsbstore"
	"github.com/ipfs/go-blockservice"
	"github.com/ipfs/go-cid"
	cbor "github.com/ipfs/go-ipld-cbor"
	ipld "github.com/ipfs/go-ipld-format"
	mdag "github.com/ipfs/go-merkledag"
	"github.com/ipfs/go-unixfs"
	uio "github.com/ipfs/go-unixfs/io"
	"github.com/ipld/go-car"
	"github.com/urfave/cli/v2"
	"golang.org/x/xerrors"
)

/// Box is a way of packing together *partial* DAGs to achieve a certain size
/// while generating the associated CAR file containing them. It is an
/// alternative to actual re-chunking the DAG nodes which can be expensive for
/// very large DAGs. A *partial* DAG is generated by excluding certain sub-DAGs
/// from it.
type Box struct {
	/// CID of the roots of the *partial* DAGs contained in this Box.
	Roots []cid.Cid
	/// CIDs of the roots of the sub-DAGs excluded from the original DAGs
	/// (delimited by Roots). We don't keep track of which sub-DAG is being
	/// trimmed from which full DAG in Roots, so to obtain the *partial* DAGs
	/// one needs to walk each DAG in Roots checking if any of its links
	/// are contained here.
	External []cid.Cid
}

func (box *Box) isExternal(link *ipld.Link) bool {
	// Boxes we're working on are likely to be in L2/L3 cache, and comparing bytes
	// is really fast, so it may not even make sense to optimize this, at least
	// unless it shows up in traces.
	for _, externalLink := range box.External {
		if bytes.Equal(externalLink.Bytes(), link.Cid.Bytes()) {
			return true
		}
	}
	return false
}

type builder struct {
	// Service to fetch the nodes in the DAGs and query its links.
	dagService ipld.DAGService

	// Maximum size allowed for each generated Box.
	boxMaxSize uint64

	// Generated boxes when packing a DAG.
	boxes []*Box
	// Used size of the current box we are packing (last one in the list). Since
	// we only pack one box at a time and don't come back to a box once we're
	// done with it we just track a single value here and not in each box.
	boxUsedSize uint64
}

func getSingleNodeSize(node ipld.Node) uint64 {
	// FIXME: How to check the size of the parent node without taking into
	//  account the children? The Node interface doesn't seem to account for
	//  that so we are going directly to the Block interface for now.
	//  We can probably get away with not accounting non-file data well, and
	//  just have some % overhead when accounting space (obviously that will
	//  break horribly with small files, but it should be good enough in the
	//  average case).
	return uint64(len(node.RawData()))
}

func (b *builder) getTreeSize(nd ipld.Node) (uint64, error) {
	switch n := nd.(type) {
	case *mdag.RawNode:
		return uint64(len(n.RawData())), nil

	case *mdag.ProtoNode:
		fsNode, err := unixfs.FSNodeFromBytes(n.Data())
		if err != nil {
			return 0, xerrors.Errorf("loading unixfs node: %w", err)
		}

		switch fsNode.Type() {
		case unixfs.TFile, unixfs.TRaw, unixfs.TDirectory, unixfs.THAMTShard:
			return n.Size()
		case unixfs.TMetadata:
			/*if len(n.Links()) == 0 {
				return nil, xerrors.New("incorrectly formatted metadata object")
			}
			child, err := n.Links()[0].GetNode(ctx, b.dagService)
			if err != nil {
				return nil, err
			}

			childpb, ok := child.(*mdag.ProtoNode)
			if !ok {
				return nil, mdag.ErrNotProtobuf
			}*/

			return 0, xerrors.Errorf("metadata object support todo")
		case unixfs.TSymlink:
			return 0, xerrors.Errorf("symlink object support todo")
		default:
			return 0, unixfs.ErrUnrecognizedType
		}
	default:
		return 0, uio.ErrUnkownNodeType
	}
}

// FIXME: Isn't this in go-units?
const kib = 1 << 10

// Get current box we are packing into. By definition now this is always the
// last created box.
func (b *builder) boxID() int {
	return len(b.boxes) - 1
}

// Get current box we are packing into.
// FIXME: Make sure from the construction of the builder that there is always one.
func (b *builder) box() *Box {
	return b.boxes[b.boxID()]
}

func (b *builder) newBox() {
	b.boxes = append(b.boxes, new(Box))
	b.boxUsedSize = 0
}

// Remaining size in the current box.
func (b *builder) boxRemainingSize() uint64 {
	// FIXME: Assert this is always `0 <= ret <= max_size`.
	return b.boxMaxSize - b.used()
}

func (b *builder) used() uint64 {
	return b.boxUsedSize
}

func (b *builder) emptyBox() bool {
	// FIXME: Assert this is always `0 <= ret <= max_size`.
	return b.used() == 0
}

// Check this size fits in the current box.
func (b *builder) fits(size uint64) bool {
	return size <= b.boxRemainingSize()
}

func (b *builder) addSize(size uint64) {
	// FIXME: Maybe assert size (`fits`).
	b.boxUsedSize += size
}

func (b *builder) packRoot(c cid.Cid) {
	b.box().Roots = append(b.box().Roots, c)
}

func (b *builder) addExternalLink(node ipld.Node) {
	b.box().External = append(b.box().External, node.Cid())
}

// Pack a DAG delimited by `initialRoot` in boxes. To enforce the maximum
// box size the DAG will be decomposed into smaller sub-DAGs if necessary.
func (b *builder) add(ctx context.Context, initialRoot ipld.Node) error {
	// LIFO queue with the roots that need to be scanned and boxed.
	// LIFO(-ish, node links pushed in reverse) should result in slightly better
	// data layout (less fragmentation in leaves) than FIFO.
	rootsToPack := []ipld.Node{initialRoot}

	for len(rootsToPack) > 0 {
		// Pick one root node from the queue.
		root := rootsToPack[len(rootsToPack)-1]
		rootsToPack = rootsToPack[:len(rootsToPack)-1]
		b.packRoot(root.Cid())

		prevNumberOfRoots := len(rootsToPack)
		err := mdag.Walk(ctx,
			// FIXME: Check if this is the standard way of fetching links.
			func(ctx context.Context, c cid.Cid) ([]*ipld.Link, error) {
				return ipld.GetLinks(ctx, b.dagService, c)
			},
			root.Cid(),
			// FIXME: The `Visit` function can't return errors, which seems odd
			//  given it should be the function that does the core of the walking
			//  logic (besides signaling if we want to continue with the walk or
			//  not). For now everything is a panic here.
			// FIXME: Check for repeated nodes? How do they count in the CAR file?
			func(nodeCid cid.Cid) bool {
				node, err := b.dagService.Get(ctx, nodeCid)
				if err != nil {
					panic(fmt.Sprintf("getting head node: %s", err))
				}

				treeSize, err := b.getTreeSize(node)
				if err != nil {
					panic(fmt.Sprintf("getting tree size: %s", err))
				}

				_, _ = fmt.Fprintf(os.Stderr, "checking node %s (tree size %d) (box %d)\n",
					node.String(), treeSize, b.boxID())

				if b.fits(treeSize) {
					b.addSize(treeSize)

					_, _ = fmt.Fprintf(os.Stderr, "entire tree fits in box (cumulative %dkib)\n", b.used()/kib)

					// The entire (sub-)graph fits so no need to keep walking it.
					return false
				}

				// Too big for the current box. We need to split parent
				// and sub-graphs (from the child nodes) and inspect their
				// sizes separately.

				// First check the size of the parent node alone.
				parentSize := getSingleNodeSize(node)
				fmt.Fprintf(os.Stderr, "tree too big, single node size: %d\n",
					parentSize)

				if b.fits(parentSize) || b.emptyBox() {
					b.addSize(parentSize)
					// Even if the node doesn't fit but this is an empty box we
					// should add it nonetheless. It means it doesn't fit in *any*
					// box so at least make sure it has its own dedicated one.
					fmt.Fprintf(os.Stderr, "added node to box (cumulative %dkib)\n",
						b.used()/kib)
					// Added the parent to the box, now process its children in the
					// next `Walk()` calls.
					return true
				}

				// Doesn't fit: process this node in the next box as a root.
				rootsToPack = append(rootsToPack, node)
				b.addExternalLink(node)
				fmt.Fprintf(os.Stderr, "node too big, adding as root for another box\n")
				// No need to visit children as not even the parent fits.
				return false
			},
			// FIXME: We're probably not ready for any type of concurrency at this point.
			mdag.Concurrency(0),
		)
		if err != nil {
			return xerrors.Errorf("error walking dag: %w", err)
		}

		if len(rootsToPack) > prevNumberOfRoots {
			// We have added internal nodes as "new" roots which means we'll
			// need a new box to put them in.
			fmt.Fprintf(os.Stderr, "***CREATING NEW BOX %d*** (previous one used %d kib)\n",
				b.boxID()+1, b.used()/kib)
			b.newBox()
		}
	}

	return nil
}

var Cmd = &cli.Command{
	Name:      "dagsplit",
	Usage:     "Cid command",
	ArgsUsage: "[root] [chunk size]",
	Action: func(cctx *cli.Context) error {
		ctx := cctx.Context

		bs, err := ipfsbstore.NewIpfsBstore(ctx, true)
		if err != nil {
			return xerrors.Errorf("getting ipfs bstore: %w", err)
		}

		if cctx.Args().Len() != 2 {
			return xerrors.Errorf("expected 2 args, root, and chuck size")
		}

		root, err := cid.Parse(cctx.Args().First())
		if err != nil {
			return xerrors.Errorf("parsing root cid: %w", err)
		}

		chunk, err := units.RAMInBytes(cctx.Args().Get(1))
		if err != nil {
			return xerrors.Errorf("parsing chunk size: %w", err)
		}

		cst := cbor.NewCborStore(bs)

		bb := builder{
			dagService: mdag.NewDAGService(blockservice.New(bs, nil)),
			boxMaxSize: uint64(chunk),
			boxes:      make([]*Box, 0),
		}
		bb.newBox() // FIXME: Encapsulate in a constructor.

		rootNd, err := bb.dagService.Get(ctx, root)
		if err != nil {
			return xerrors.Errorf("getting head node: %w", err)
		}

		err = bb.add(ctx, rootNd)
		if err != nil {
			return err
		}

		boxCids := make([]cid.Cid, len(bb.boxes))
		for i, box := range bb.boxes {
			boxCids[i], err = cst.Put(ctx, box)
			if err != nil {
				return xerrors.Errorf("putting box %d: %w", i, err)
			}

			fmt.Printf("BOX %d: %s\n", i, boxCids[i])
		}

		// =====================
		// CAR generation logic.
		// =====================
		// FIXME: Should be decoupled from the above (probably in its own
		//  separate command).

		CAR_OUT_DIR := "dagsplitter-car-files"
		if _, err := os.Stat(CAR_OUT_DIR); os.IsNotExist(err) {
			if err := os.Mkdir(CAR_OUT_DIR, os.ModePerm); err != nil {
				return xerrors.Errorf("creating directory: %w", err)
			}
		} else if err != nil {
			return xerrors.Errorf("querying directory stat: %w", err)
		}

		for _, boxCid := range boxCids {
			box := Box{}
			if err := cst.Get(ctx, boxCid, &box); err != nil {
				// FIXME: We could just retain the created boxes but trying
				//  to make it more decoupled (we might not have them available
				//  by the time this is called).
				return xerrors.Errorf("failed retrieving box: %w", err)
			}

			//_, _ = fmt.Fprintf(os.Stderr, "Creating car with roots: %v\n", box.Roots)

			out := new(bytes.Buffer)
			if err := car.WriteCarWithWalker(context.TODO(), bb.dagService, box.Roots, out, BoxCarWalkFunc(&box)); err != nil {
				return xerrors.Errorf("write car failed: %w", err)
			}

			if err := ioutil.WriteFile(filepath.Join(CAR_OUT_DIR, boxCid.String()+".car"),
				out.Bytes(), 0644); err != nil {
				return xerrors.Errorf("write file failed: %w", err)
			}
		}

		return nil
	},
}

func BoxCarWalkFunc(box *Box) func(nd ipld.Node) (out []*ipld.Link, err error) {
	return func(nd ipld.Node) (out []*ipld.Link, err error) {
		for _, link := range nd.Links() {

			// Do not walk into nodes external to the current `box`.
			if box.isExternal(link) {
				//_, _ = fmt.Fprintf(os.Stderr, "Found external link, skipping from CAR generation: %s\n", link.Cid.String())
				continue
			}

			// Taken from the original `gen.CarWalkFunc`:
			//  Filecoin sector commitment CIDs (CommD (padded/truncated sha256
			//  binary tree), CommR (basically magic tree)). Those are linked
			//  directly in the chain state, so this avoids trying to accidentally
			//  walk over a few exabytes of data.
			// FIXME: Avoid duplicating this code from the original.
			pref := link.Cid.Prefix()
			if pref.Codec == cid.FilCommitmentSealed || pref.Codec == cid.FilCommitmentUnsealed {
				continue
			}

			out = append(out, link)
		}

		return out, nil
	}
}

// FIXME: Add real test. For now check that the output matches across refactors.
// ```bash
// ./lotus-shed dagsplit QmRLzQZ5efau2kJLfZRm9Guo1DxiBp3xCAVf6EuPCqKdsB 1M`
// # BOX 0: bafy2bzaceabbm7sc5cltufptovdjwxdbvsxodnrrr5aafcfxqgc73czfpuc4m
// # BOX 1: bafy2bzacebr7lznfzlr4ippmuwer7ntnlxdu6q4hn6gypywn7f64q2knxw6bw
// ls -la dagsplitter-car-files/
// # 1055442 feb  3 21:24 bafy2bzacecuyghj5wmna3xhkhkpon4lioaj5utcva7xqljz6vqaslze3wv7wo.car
// # 416285 feb  3 21:24 bafy2bzacedqfsq3jggpowtmjhsseflp6tu56gnkoyrgnobb64oxtmzf2uzrei.car
// ```
