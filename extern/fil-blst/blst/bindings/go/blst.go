//!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
// DO NOT EDIT THIS FILE!!
// The file is generated from *.tgo by generate.py
//!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
/*
 * Copyright Supranational LLC
 * Licensed under the Apache License, Version 2.0, see LICENSE for details.
 * SPDX-License-Identifier: Apache-2.0
 */

package blst

// #cgo CFLAGS: -I${SRCDIR}/.. -I${SRCDIR}/../../build -I${SRCDIR}/../../src -D__BLST_CGO__
// #cgo amd64 CFLAGS: -D__ADX__ -mno-avx
// #include "blst.h"
import "C"
import (
	"fmt"
	"runtime"
	"sync"
	"sync/atomic"
)

const BLST_SCALAR_BYTES = 256 / 8
const BLST_FP_BYTES = 384 / 8
const BLST_P1_COMPRESS_BYTES = BLST_FP_BYTES
const BLST_P1_SERIALIZE_BYTES = BLST_FP_BYTES * 2
const BLST_P2_COMPRESS_BYTES = BLST_FP_BYTES * 2
const BLST_P2_SERIALIZE_BYTES = BLST_FP_BYTES * 4

type Scalar = C.blst_scalar
type Fp = C.blst_fp
type Fp2 = C.blst_fp2
type Fp6 = C.blst_fp6
type Fp12 = C.blst_fp12
type P1 = C.blst_p1
type P2 = C.blst_p2
type P1Affine = C.blst_p1_affine
type P2Affine = C.blst_p2_affine
type Message = []byte
type Pairing = []uint64
type SecretKey = Scalar

//
// Configuration
//

var maxProcs = initMaxProcs()

func initMaxProcs() int {
	maxProcs := runtime.GOMAXPROCS(0) - 1
	if maxProcs <= 0 {
		maxProcs = 1
	}
	return maxProcs
}

func SetMaxProcs(max int) {
	if max <= 0 {
		max = 1
	}
	maxProcs = max
}

//
// Secret key
//
func KeyGen(ikm []byte, optional ...[]byte) *SecretKey {
	var sk SecretKey
	var info []byte
	var infoP *C.byte
	if len(optional) > 0 {
		info = optional[0]
		infoP = (*C.byte)(&info[0])
	}
	if len(ikm) < 32 {
		return nil
	}
	C.blst_keygen(&sk, (*C.byte)(&ikm[0]), C.size_t(len(ikm)),
		infoP, C.size_t(len(info)))
	return &sk
}

//
// Pairing
//
func PairingCtx(hash_or_encode bool, DST []byte) Pairing {
	ctx := make([]uint64, C.blst_pairing_sizeof()/8)
	var uDST *C.byte
	if DST != nil {
		uDST = (*C.byte)(&DST[0])
	}
	C.blst_pairing_init((*C.blst_pairing)(&ctx[0]), C.bool(hash_or_encode),
		uDST, C.size_t(len(DST)))
	return ctx
}

func PairingAggregatePkInG1(ctx Pairing, PK *P1Affine, sig *P2Affine,
	msg []byte,
	optional ...[]byte) int { // aug
	var aug []byte
	var uaug *C.byte
	if len(optional) > 0 {
		aug = optional[0]
		if aug != nil {
			uaug = (*C.byte)(&aug[0])
		}
	}
	var umsg *C.byte
	if msg != nil {
		umsg = (*C.byte)(&msg[0])
	}

	r := C.blst_pairing_aggregate_pk_in_g1((*C.blst_pairing)(&ctx[0]), PK, sig,
		umsg, C.size_t(len(msg)),
		uaug, C.size_t(len(aug)))

	return int(r)
}

func PairingAggregatePkInG2(ctx Pairing, PK *P2Affine, sig *P1Affine,
	msg []byte,
	optional ...[]byte) int { // aug
	var aug []byte
	var uaug *C.byte
	if len(optional) > 0 {
		aug = optional[0]
		if aug != nil {
			uaug = (*C.byte)(&aug[0])
		}
	}
	var umsg *C.byte
	if msg != nil {
		umsg = (*C.byte)(&msg[0])
	}

	r := C.blst_pairing_aggregate_pk_in_g2((*C.blst_pairing)(&ctx[0]), PK, sig,
		umsg, C.size_t(len(msg)),
		uaug, C.size_t(len(aug)))

	return int(r)
}

func PairingMulNAggregatePkInG1(ctx Pairing, PK *P1Affine, sig *P2Affine,
	rand *Scalar, randBits int, msg []byte,
	optional ...[]byte) int { // aug
	var aug []byte
	var uaug *C.byte
	if len(optional) > 0 {
		aug = optional[0]
		if aug != nil {
			uaug = (*C.byte)(&aug[0])
		}
	}
	var umsg *C.byte
	if msg != nil {
		umsg = (*C.byte)(&msg[0])
	}

	r := C.blst_pairing_mul_n_aggregate_pk_in_g1((*C.blst_pairing)(&ctx[0]),
		PK, sig,
		&rand.l[0], C.size_t(randBits),
		umsg, C.size_t(len(msg)),
		uaug, C.size_t(len(aug)))

	return int(r)
}

func PairingMulNAggregatePkInG2(ctx Pairing, PK *P2Affine, sig *P1Affine,
	rand *Scalar, randBits int, msg []byte,
	optional ...[]byte) int { // aug
	var aug []byte
	var uaug *C.byte
	if len(optional) > 0 {
		aug = optional[0]
		if aug != nil {
			uaug = (*C.byte)(&aug[0])
		}
	}
	var umsg *C.byte
	if msg != nil {
		umsg = (*C.byte)(&msg[0])
	}

	r := C.blst_pairing_mul_n_aggregate_pk_in_g2((*C.blst_pairing)(&ctx[0]),
		PK, sig,
		&rand.l[0], C.size_t(randBits),
		umsg, C.size_t(len(msg)),
		uaug, C.size_t(len(aug)))

	return int(r)
}

func PairingCommit(ctx Pairing) {
	C.blst_pairing_commit((*C.blst_pairing)(&ctx[0]))
}

func PairingMerge(ctx Pairing, ctx1 Pairing) int {
	r := C.blst_pairing_merge((*C.blst_pairing)(&ctx[0]),
		(*C.blst_pairing)(&ctx1[0]))
	return int(r)
}

func PairingFinalVerify(ctx Pairing, optional ...*Fp12) bool {
	var gtsig *Fp12 = nil
	if len(optional) > 0 {
		gtsig = optional[0]
	}
	return bool(C.blst_pairing_finalverify((*C.blst_pairing)(&ctx[0]), gtsig))
}

func Fp12One() Fp12 {
	return *C.blst_fp12_one()
}

//
// MIN-PK
//

//
// PublicKey
//

func (pk *P1Affine) From(s *Scalar) *P1Affine {
	C.blst_sk_to_pk2_in_g1(nil, pk, s)
	return pk
}

//
// Sign
//

func (sig *P2Affine) Sign(sk *SecretKey, msg []byte, dst []byte,
	optional ...interface{}) *P2Affine {
	augSingle, aug, useHash, ok := parseOpts(optional...)
	if !ok || len(aug) != 0 {
		return nil
	}

	var q *P2
	if useHash {
		q = HashToG2(msg, dst, augSingle)
	} else {
		q = EncodeToG2(msg, dst, augSingle)
	}
	C.blst_sign_pk2_in_g1(nil, sig, q, sk)
	return sig
}

//
// Signature
//

// Functions to return a signature and public key+augmentation tuple.
// This enables point decompression (if needed) to happen in parallel.
type sigGetterP2 func() *P2Affine
type pkGetterP1 func(i uint32, temp *P1Affine) (*P1Affine, []byte)

// Single verify with decompressed pk
func (sig *P2Affine) Verify(pk *P1Affine, msg Message, dst []byte,
	optional ...interface{}) bool { // useHash bool, aug []byte

	// CLEANUP!!
	// Check for infinities (eth spec)
	var zeroSig P2Affine
	var zeroPk P1Affine
	if pk.Equals(&zeroPk) && sig.Equals(&zeroSig) {
		return true
	}
	// CLEANUP!!

	aug, _, useHash, ok := parseOpts(optional...)
	if !ok {
		return false
	}
	return sig.AggregateVerify([]*P1Affine{pk}, []Message{msg}, dst,
		useHash, [][]byte{aug})
}

// Single verify with compressed pk
// Uses a dummy signature to get the correct type
func (dummy *P2Affine) VerifyCompressed(sig []byte, pk []byte,
	msg Message, dst []byte,
	optional ...bool) bool { // useHash bool, usePksAsAugs bool

	// CLEANUP!!
	// Check for infinities (eth spec)
	// Need to support serialized points here?
	if len(sig) == BLST_P2_COMPRESS_BYTES && sig[0] == 0xc0 &&
		len(pk) == BLST_P1_COMPRESS_BYTES && pk[0] == 0xc0 &&
		bytesAllZero(sig[1:]) && bytesAllZero(pk[1:]) {
		return true
	}
	// CLEANUP!!

	return dummy.AggregateVerifyCompressed(sig, [][]byte{pk},
		[]Message{msg}, dst, optional...)
}

// Aggregate verify with uncompressed signature and public keys
func (sig *P2Affine) AggregateVerify(pks []*P1Affine, msgs []Message,
	dst []byte,
	optional ...interface{}) bool { // useHash bool, augs [][]byte

	// sanity checks and argument parsing
	if len(pks) != len(msgs) {
		return false
	}
	_, augs, useHash, ok := parseOpts(optional...)
	useAugs := len(augs) != 0
	if !ok || (useAugs && len(augs) != len(msgs)) {
		return false
	}

	sigFn := func() *P2Affine {
		return sig
	}

	pkFn := func(i uint32, _ *P1Affine) (*P1Affine, []byte) {
		if useAugs {
			return pks[i], augs[i]
		} else {
			return pks[i], nil
		}
	}

	return coreAggregateVerifyPkInG1(sigFn, pkFn, msgs, dst, useHash)
}

// Aggregate verify with compressed signature and public keys
// Uses a dummy signature to get the correct type
func (dummy *P2Affine) AggregateVerifyCompressed(sig []byte, pks [][]byte,
	msgs []Message, dst []byte,
	optional ...bool) bool { // useHash bool, usePksAsAugs bool

	// sanity checks and argument parsing
	if len(pks) != len(msgs) {
		return false
	}
	useHash := true
	if len(optional) > 0 {
		useHash = optional[0]
	}
	usePksAsAugs := false
	if len(optional) > 1 {
		usePksAsAugs = optional[1]
	}

	sigFn := func() *P2Affine {
		sigP := new(P2Affine)
		if sig[0]&0x80 == 0 {
			// Not compressed
			if sigP.Deserialize(sig) == nil {
				return nil
			}
		} else {
			if sigP.Uncompress(sig) == nil {
				return nil
			}
		}
		return sigP
	}
	pkFn := func(i uint32, pk *P1Affine) (*P1Affine, []byte) {
		bytes := pks[i]
		if len(bytes) == 0 {
			return nil, nil
		}
		if bytes[0]&0x80 == 0 {
			// Not compressed
			if pk.Deserialize(bytes) == nil {
				return nil, nil
			}
		} else {
			if pk.Uncompress(bytes) == nil {
				return nil, nil
			}
		}
		if usePksAsAugs {
			return pk, bytes
		}
		return pk, nil
	}
	return coreAggregateVerifyPkInG1(sigFn, pkFn, msgs, dst, useHash)
}

// TODO: check message uniqueness
func coreAggregateVerifyPkInG1(sigFn sigGetterP2, pkFn pkGetterP1,
	msgs []Message, dst []byte,
	optional ...bool) bool { // useHash

	n := len(msgs)
	if n == 0 {
		return true
	}

	useHash := true
	if len(optional) > 0 {
		useHash = optional[0]
	}

	numCores := runtime.GOMAXPROCS(0)
	numThreads := maxProcs
	if numThreads > numCores {
		numThreads = numCores
	}
	if numThreads > n {
		numThreads = n
	}
	// Each thread will determine next message to process by atomically
	// incrementing curItem, process corresponding pk,msg[,aug] tuple and
	// repeat until n is exceeded.  The resulting accumulations will be
	// fed into the msgsCh channel.
	msgsCh := make(chan Pairing, numThreads)
	valid := int32(1)
	curItem := uint32(0)
	mutex := sync.Mutex{}

	mutex.Lock()
	for tid := 0; tid < numThreads; tid++ {
		go func() {
			pairing := PairingCtx(useHash, dst)
			var temp P1Affine
			for atomic.LoadInt32(&valid) > 0 {
				// Get a work item
				work := atomic.AddUint32(&curItem, 1) - 1
				if work >= uint32(n) {
					break
				} else if work == 0 && maxProcs == numCores-1 &&
					numThreads == maxProcs {
					// Avoid consuming all cores by waiting until the
					// main thread has completed its miller loop before
					// proceeding.
					mutex.Lock()
					mutex.Unlock()
				}

				// Pull Public Key and augmentation blob
				curPk, aug := pkFn(work, &temp)
				if curPk == nil {
					atomic.StoreInt32(&valid, 0)
					break
				}

				// Pairing and accumulate
				PairingAggregatePkInG1(pairing, curPk, nil, msgs[work], aug)

				// application might have some async work to do
				runtime.Gosched()
			}
			if atomic.LoadInt32(&valid) > 0 {
				PairingCommit(pairing)
				msgsCh <- pairing
			} else {
				msgsCh <- nil
			}
		}()
	}

	// Uncompress and check signature
	var gtsig Fp12
	sig := sigFn()
	if sig == nil {
		atomic.StoreInt32(&valid, 0)
	} else {
		C.blst_aggregated_in_g2(&gtsig, sig)
	}
	mutex.Unlock()

	// Accumulate the thread results
	var pairings Pairing
	for i := 0; i < numThreads; i++ {
		msg := <-msgsCh
		if msg != nil {
			if pairings == nil {
				pairings = msg
			} else {
				PairingMerge(pairings, msg)
			}
		}
	}
	if atomic.LoadInt32(&valid) == 0 || pairings == nil {
		return false
	}

	return PairingFinalVerify(pairings, &gtsig)
}

func (sig *P2Affine) FastAggregateVerify(pks []*P1Affine, msg Message,
	dst []byte,
	optional ...interface{}) bool { // pass-through to Verify
	n := len(pks)

	// TODO: return value for length zero?
	if n == 0 {
		return false
	}

	aggregator := new(P1Aggregate).Aggregate(pks)
	if aggregator == nil {
		return false
	}
	pkAff := aggregator.ToAffine()

	// Verify
	return sig.Verify(pkAff, msg, dst, optional...)
}

func (dummy *P2Affine) MultipleAggregateVerify(sigs []*P2Affine,
	pks []*P1Affine, msgs []Message, dst []byte, randFn func(*Scalar),
	randBits int,
	optional ...interface{}) bool { // useHash

	// Sanity checks and argument parsing
	if len(pks) != len(msgs) || len(pks) != len(sigs) {
		return false
	}
	_, augs, useHash, ok := parseOpts(optional...)
	useAugs := len(augs) != 0
	if !ok || (useAugs && len(augs) != len(msgs)) {
		return false
	}

	paramsFn :=
		func(work uint32, sig *P2Affine, pk *P1Affine, rand *Scalar) (
			*P2Affine, *P1Affine, *Scalar, []byte) {
			randFn(rand)
			var aug []byte
			if useAugs {
				aug = augs[work]
			}
			return sigs[work], pks[work], rand, aug
		}

	return multipleAggregateVerifyPkInG1(paramsFn, msgs, dst,
		randBits, useHash)
}

type mulAggGetterPkInG1 func(work uint32, sig *P2Affine, pk *P1Affine,
	rand *Scalar) (*P2Affine, *P1Affine, *Scalar, []byte)

func multipleAggregateVerifyPkInG1(paramsFn mulAggGetterPkInG1, msgs []Message,
	dst []byte, randBits int,
	optional ...bool) bool { // useHash
	n := len(msgs)
	if n == 0 {
		return true
	}

	useHash := true
	if len(optional) > 0 {
		useHash = optional[0]
	}

	numCores := runtime.GOMAXPROCS(0)
	numThreads := maxProcs
	if numThreads > numCores {
		numThreads = numCores
	}
	if numThreads > n {
		numThreads = n
	}
	// Each thread will determine next message to process by atomically
	// incrementing curItem, process corresponding pk,msg[,aug] tuple and
	// repeat until n is exceeded.  The resulting accumulations will be
	// fed into the msgsCh channel.
	msgsCh := make(chan Pairing, numThreads)
	valid := int32(1)
	curItem := uint32(0)

	for tid := 0; tid < numThreads; tid++ {
		go func() {
			pairing := PairingCtx(useHash, dst)
			var tempRand Scalar
			var tempPk P1Affine
			var tempSig P2Affine
			for atomic.LoadInt32(&valid) > 0 {
				// Get a work item
				work := atomic.AddUint32(&curItem, 1) - 1
				if work >= uint32(n) {
					break
				}

				curSig, curPk, curRand, aug := paramsFn(work, &tempSig,
					&tempPk, &tempRand)

				if PairingMulNAggregatePkInG1(pairing, curPk, curSig, curRand,
					randBits, msgs[work], aug) !=
					C.BLST_SUCCESS {
					atomic.StoreInt32(&valid, 0)
					break
				}

				// application might have some async work to do
				runtime.Gosched()
			}
			if atomic.LoadInt32(&valid) > 0 {
				PairingCommit(pairing)
				msgsCh <- pairing
			} else {
				msgsCh <- nil
			}
		}()
	}

	// Accumulate the thread results
	var pairings Pairing
	for i := 0; i < numThreads; i++ {
		msg := <-msgsCh
		if msg != nil {
			if pairings == nil {
				pairings = msg
			} else {
				PairingMerge(pairings, msg)
			}
		}
	}
	if atomic.LoadInt32(&valid) == 0 || pairings == nil {
		return false
	}

	return PairingFinalVerify(pairings, nil)
}

//
// Aggregate P2
//

type aggGetterP2 func(i uint32, temp *P2Affine) *P2Affine
type P2Aggregate struct {
	v *P2
}

// Aggregate uncompressed elements
func (agg *P2Aggregate) Aggregate(elmts []*P2Affine) *P2Aggregate {
	if len(elmts) == 0 {
		return agg
	}
	getter := func(i uint32, _ *P2Affine) *P2Affine { return elmts[i] }
	if !agg.aggregate(getter, len(elmts)) {
		return nil
	}
	return agg
}

// Aggregate compressed elements
func (agg *P2Aggregate) AggregateCompressed(elmts [][]byte) *P2Aggregate {
	if len(elmts) == 0 {
		return agg
	}
	getter := func(i uint32, p *P2Affine) *P2Affine {
		bytes := elmts[i]
		if len(bytes) == 0 {
			return nil
		}
		if bytes[0]&0x80 == 0 {
			// Not compressed
			if p.Deserialize(bytes) == nil {
				return nil
			}
		} else {
			if p.Uncompress(bytes) == nil {
				return nil
			}
		}
		return p
	}
	if !agg.aggregate(getter, len(elmts)) {
		return nil
	}
	return agg
}

func (agg *P2Aggregate) AddAggregate(other *P2Aggregate) *P2Aggregate {
	if other.v == nil {
		// do nothing
	} else if agg.v == nil {
		agg.v = other.v
	} else {
		C.blst_p2_add(agg.v, agg.v, other.v)
	}
	return agg
}

func (agg *P2Aggregate) Add(elmt *P2Affine) *P2Aggregate {
	if agg.v == nil {
		agg.v = new(P2)
		C.blst_p2_from_affine(agg.v, elmt)
	} else {
		C.blst_p2_add_or_double_affine(agg.v, agg.v, elmt)
	}
	return agg
}

func (agg *P2Aggregate) ToAffine() *P2Affine {
	if agg.v == nil {
		return new(P2Affine)
	}
	return agg.v.ToAffine()
}

func (agg *P2Aggregate) aggregate(getter aggGetterP2, n int) bool {
	if n == 0 {
		return true
	}
	// operations are considered short enough for not to care about
	// keeping one core free...
	numThreads := runtime.GOMAXPROCS(0)
	if numThreads > n {
		numThreads = n
	}

	valid := int32(1)
	type result struct {
		agg   *P2
		empty bool
	}
	msgs := make(chan result, numThreads)
	curItem := uint32(0)
	for tid := 0; tid < numThreads; tid++ {
		go func() {
			first := true
			var agg P2
			var temp P2Affine
			for atomic.LoadInt32(&valid) > 0 {
				// Get a work item
				work := atomic.AddUint32(&curItem, 1) - 1
				if work >= uint32(n) {
					break
				}

				// Signature validate
				curElmt := getter(work, &temp)
				if curElmt == nil {
					atomic.StoreInt32(&valid, 0)
					break
				}
				if first {
					C.blst_p2_from_affine(&agg, curElmt)
					first = false
				} else {
					C.blst_p2_add_or_double_affine(&agg, &agg, curElmt)
				}
				// application might have some async work to do
				runtime.Gosched()
			}
			if first {
				msgs <- result{nil, true}
			} else if atomic.LoadInt32(&valid) > 0 {
				msgs <- result{&agg, false}
			} else {
				msgs <- result{nil, false}
			}
		}()
	}

	// Accumulate the thread results
	first := agg.v == nil
	validLocal := true
	for i := 0; i < numThreads; i++ {
		msg := <-msgs
		if !validLocal || msg.empty {
			// do nothing
		} else if msg.agg == nil {
			validLocal = false
			// This should be unnecessary but seems safer
			atomic.StoreInt32(&valid, 0)
		} else {
			if first {
				agg.v = msg.agg
				first = false
			} else {
				C.blst_p2_add(agg.v, agg.v, msg.agg)
			}
		}
	}
	if atomic.LoadInt32(&valid) == 0 {
		agg.v = nil
		return false
	}
	return true
}

//
// MIN-SIG
//

//
// PublicKey
//

func (pk *P2Affine) From(s *Scalar) *P2Affine {
	C.blst_sk_to_pk2_in_g2(nil, pk, s)
	return pk
}

//
// Sign
//

func (sig *P1Affine) Sign(sk *SecretKey, msg []byte, dst []byte,
	optional ...interface{}) *P1Affine {
	augSingle, aug, useHash, ok := parseOpts(optional...)
	if !ok || len(aug) != 0 {
		return nil
	}

	var q *P1
	if useHash {
		q = HashToG1(msg, dst, augSingle)
	} else {
		q = EncodeToG1(msg, dst, augSingle)
	}
	C.blst_sign_pk2_in_g2(nil, sig, q, sk)
	return sig
}

//
// Signature
//

// Functions to return a signature and public key+augmentation tuple.
// This enables point decompression (if needed) to happen in parallel.
type sigGetterP1 func() *P1Affine
type pkGetterP2 func(i uint32, temp *P2Affine) (*P2Affine, []byte)

// Single verify with decompressed pk
func (sig *P1Affine) Verify(pk *P2Affine, msg Message, dst []byte,
	optional ...interface{}) bool { // useHash bool, aug []byte

	// CLEANUP!!
	// Check for infinities (eth spec)
	var zeroSig P1Affine
	var zeroPk P2Affine
	if pk.Equals(&zeroPk) && sig.Equals(&zeroSig) {
		return true
	}
	// CLEANUP!!

	aug, _, useHash, ok := parseOpts(optional...)
	if !ok {
		return false
	}
	return sig.AggregateVerify([]*P2Affine{pk}, []Message{msg}, dst,
		useHash, [][]byte{aug})
}

// Single verify with compressed pk
// Uses a dummy signature to get the correct type
func (dummy *P1Affine) VerifyCompressed(sig []byte, pk []byte,
	msg Message, dst []byte,
	optional ...bool) bool { // useHash bool, usePksAsAugs bool

	// CLEANUP!!
	// Check for infinities (eth spec)
	// Need to support serialized points here?
	if len(sig) == BLST_P1_COMPRESS_BYTES && sig[0] == 0xc0 &&
		len(pk) == BLST_P2_COMPRESS_BYTES && pk[0] == 0xc0 &&
		bytesAllZero(sig[1:]) && bytesAllZero(pk[1:]) {
		return true
	}
	// CLEANUP!!

	return dummy.AggregateVerifyCompressed(sig, [][]byte{pk},
		[]Message{msg}, dst, optional...)
}

// Aggregate verify with uncompressed signature and public keys
func (sig *P1Affine) AggregateVerify(pks []*P2Affine, msgs []Message,
	dst []byte,
	optional ...interface{}) bool { // useHash bool, augs [][]byte

	// sanity checks and argument parsing
	if len(pks) != len(msgs) {
		return false
	}
	_, augs, useHash, ok := parseOpts(optional...)
	useAugs := len(augs) != 0
	if !ok || (useAugs && len(augs) != len(msgs)) {
		return false
	}

	sigFn := func() *P1Affine {
		return sig
	}

	pkFn := func(i uint32, _ *P2Affine) (*P2Affine, []byte) {
		if useAugs {
			return pks[i], augs[i]
		} else {
			return pks[i], nil
		}
	}

	return coreAggregateVerifyPkInG2(sigFn, pkFn, msgs, dst, useHash)
}

// Aggregate verify with compressed signature and public keys
// Uses a dummy signature to get the correct type
func (dummy *P1Affine) AggregateVerifyCompressed(sig []byte, pks [][]byte,
	msgs []Message, dst []byte,
	optional ...bool) bool { // useHash bool, usePksAsAugs bool

	// sanity checks and argument parsing
	if len(pks) != len(msgs) {
		return false
	}
	useHash := true
	if len(optional) > 0 {
		useHash = optional[0]
	}
	usePksAsAugs := false
	if len(optional) > 1 {
		usePksAsAugs = optional[1]
	}

	sigFn := func() *P1Affine {
		sigP := new(P1Affine)
		if sig[0]&0x80 == 0 {
			// Not compressed
			if sigP.Deserialize(sig) == nil {
				return nil
			}
		} else {
			if sigP.Uncompress(sig) == nil {
				return nil
			}
		}
		return sigP
	}
	pkFn := func(i uint32, pk *P2Affine) (*P2Affine, []byte) {
		bytes := pks[i]
		if len(bytes) == 0 {
			return nil, nil
		}
		if bytes[0]&0x80 == 0 {
			// Not compressed
			if pk.Deserialize(bytes) == nil {
				return nil, nil
			}
		} else {
			if pk.Uncompress(bytes) == nil {
				return nil, nil
			}
		}
		if usePksAsAugs {
			return pk, bytes
		}
		return pk, nil
	}
	return coreAggregateVerifyPkInG2(sigFn, pkFn, msgs, dst, useHash)
}

// TODO: check message uniqueness
func coreAggregateVerifyPkInG2(sigFn sigGetterP1, pkFn pkGetterP2,
	msgs []Message, dst []byte,
	optional ...bool) bool { // useHash

	n := len(msgs)
	if n == 0 {
		return true
	}

	useHash := true
	if len(optional) > 0 {
		useHash = optional[0]
	}

	numCores := runtime.GOMAXPROCS(0)
	numThreads := maxProcs
	if numThreads > numCores {
		numThreads = numCores
	}
	if numThreads > n {
		numThreads = n
	}
	// Each thread will determine next message to process by atomically
	// incrementing curItem, process corresponding pk,msg[,aug] tuple and
	// repeat until n is exceeded.  The resulting accumulations will be
	// fed into the msgsCh channel.
	msgsCh := make(chan Pairing, numThreads)
	valid := int32(1)
	curItem := uint32(0)
	mutex := sync.Mutex{}

	mutex.Lock()
	for tid := 0; tid < numThreads; tid++ {
		go func() {
			pairing := PairingCtx(useHash, dst)
			var temp P2Affine
			for atomic.LoadInt32(&valid) > 0 {
				// Get a work item
				work := atomic.AddUint32(&curItem, 1) - 1
				if work >= uint32(n) {
					break
				} else if work == 0 && maxProcs == numCores-1 &&
					numThreads == maxProcs {
					// Avoid consuming all cores by waiting until the
					// main thread has completed its miller loop before
					// proceeding.
					mutex.Lock()
					mutex.Unlock()
				}

				// Pull Public Key and augmentation blob
				curPk, aug := pkFn(work, &temp)
				if curPk == nil {
					atomic.StoreInt32(&valid, 0)
					break
				}

				// Pairing and accumulate
				PairingAggregatePkInG2(pairing, curPk, nil, msgs[work], aug)

				// application might have some async work to do
				runtime.Gosched()
			}
			if atomic.LoadInt32(&valid) > 0 {
				PairingCommit(pairing)
				msgsCh <- pairing
			} else {
				msgsCh <- nil
			}
		}()
	}

	// Uncompress and check signature
	var gtsig Fp12
	sig := sigFn()
	if sig == nil {
		atomic.StoreInt32(&valid, 0)
	} else {
		C.blst_aggregated_in_g1(&gtsig, sig)
	}
	mutex.Unlock()

	// Accumulate the thread results
	var pairings Pairing
	for i := 0; i < numThreads; i++ {
		msg := <-msgsCh
		if msg != nil {
			if pairings == nil {
				pairings = msg
			} else {
				PairingMerge(pairings, msg)
			}
		}
	}
	if atomic.LoadInt32(&valid) == 0 || pairings == nil {
		return false
	}

	return PairingFinalVerify(pairings, &gtsig)
}

func (sig *P1Affine) FastAggregateVerify(pks []*P2Affine, msg Message,
	dst []byte,
	optional ...interface{}) bool { // pass-through to Verify
	n := len(pks)

	// TODO: return value for length zero?
	if n == 0 {
		return false
	}

	aggregator := new(P2Aggregate).Aggregate(pks)
	if aggregator == nil {
		return false
	}
	pkAff := aggregator.ToAffine()

	// Verify
	return sig.Verify(pkAff, msg, dst, optional...)
}

func (dummy *P1Affine) MultipleAggregateVerify(sigs []*P1Affine,
	pks []*P2Affine, msgs []Message, dst []byte, randFn func(*Scalar),
	randBits int,
	optional ...interface{}) bool { // useHash

	// Sanity checks and argument parsing
	if len(pks) != len(msgs) || len(pks) != len(sigs) {
		return false
	}
	_, augs, useHash, ok := parseOpts(optional...)
	useAugs := len(augs) != 0
	if !ok || (useAugs && len(augs) != len(msgs)) {
		return false
	}

	paramsFn :=
		func(work uint32, sig *P1Affine, pk *P2Affine, rand *Scalar) (
			*P1Affine, *P2Affine, *Scalar, []byte) {
			randFn(rand)
			var aug []byte
			if useAugs {
				aug = augs[work]
			}
			return sigs[work], pks[work], rand, aug
		}

	return multipleAggregateVerifyPkInG2(paramsFn, msgs, dst,
		randBits, useHash)
}

type mulAggGetterPkInG2 func(work uint32, sig *P1Affine, pk *P2Affine,
	rand *Scalar) (*P1Affine, *P2Affine, *Scalar, []byte)

func multipleAggregateVerifyPkInG2(paramsFn mulAggGetterPkInG2, msgs []Message,
	dst []byte, randBits int,
	optional ...bool) bool { // useHash
	n := len(msgs)
	if n == 0 {
		return true
	}

	useHash := true
	if len(optional) > 0 {
		useHash = optional[0]
	}

	numCores := runtime.GOMAXPROCS(0)
	numThreads := maxProcs
	if numThreads > numCores {
		numThreads = numCores
	}
	if numThreads > n {
		numThreads = n
	}
	// Each thread will determine next message to process by atomically
	// incrementing curItem, process corresponding pk,msg[,aug] tuple and
	// repeat until n is exceeded.  The resulting accumulations will be
	// fed into the msgsCh channel.
	msgsCh := make(chan Pairing, numThreads)
	valid := int32(1)
	curItem := uint32(0)

	for tid := 0; tid < numThreads; tid++ {
		go func() {
			pairing := PairingCtx(useHash, dst)
			var tempRand Scalar
			var tempPk P2Affine
			var tempSig P1Affine
			for atomic.LoadInt32(&valid) > 0 {
				// Get a work item
				work := atomic.AddUint32(&curItem, 1) - 1
				if work >= uint32(n) {
					break
				}

				curSig, curPk, curRand, aug := paramsFn(work, &tempSig,
					&tempPk, &tempRand)

				if PairingMulNAggregatePkInG2(pairing, curPk, curSig, curRand,
					randBits, msgs[work], aug) !=
					C.BLST_SUCCESS {
					atomic.StoreInt32(&valid, 0)
					break
				}

				// application might have some async work to do
				runtime.Gosched()
			}
			if atomic.LoadInt32(&valid) > 0 {
				PairingCommit(pairing)
				msgsCh <- pairing
			} else {
				msgsCh <- nil
			}
		}()
	}

	// Accumulate the thread results
	var pairings Pairing
	for i := 0; i < numThreads; i++ {
		msg := <-msgsCh
		if msg != nil {
			if pairings == nil {
				pairings = msg
			} else {
				PairingMerge(pairings, msg)
			}
		}
	}
	if atomic.LoadInt32(&valid) == 0 || pairings == nil {
		return false
	}

	return PairingFinalVerify(pairings, nil)
}

//
// Aggregate P1
//

type aggGetterP1 func(i uint32, temp *P1Affine) *P1Affine
type P1Aggregate struct {
	v *P1
}

// Aggregate uncompressed elements
func (agg *P1Aggregate) Aggregate(elmts []*P1Affine) *P1Aggregate {
	if len(elmts) == 0 {
		return agg
	}
	getter := func(i uint32, _ *P1Affine) *P1Affine { return elmts[i] }
	if !agg.aggregate(getter, len(elmts)) {
		return nil
	}
	return agg
}

// Aggregate compressed elements
func (agg *P1Aggregate) AggregateCompressed(elmts [][]byte) *P1Aggregate {
	if len(elmts) == 0 {
		return agg
	}
	getter := func(i uint32, p *P1Affine) *P1Affine {
		bytes := elmts[i]
		if len(bytes) == 0 {
			return nil
		}
		if bytes[0]&0x80 == 0 {
			// Not compressed
			if p.Deserialize(bytes) == nil {
				return nil
			}
		} else {
			if p.Uncompress(bytes) == nil {
				return nil
			}
		}
		return p
	}
	if !agg.aggregate(getter, len(elmts)) {
		return nil
	}
	return agg
}

func (agg *P1Aggregate) AddAggregate(other *P1Aggregate) *P1Aggregate {
	if other.v == nil {
		// do nothing
	} else if agg.v == nil {
		agg.v = other.v
	} else {
		C.blst_p1_add(agg.v, agg.v, other.v)
	}
	return agg
}

func (agg *P1Aggregate) Add(elmt *P1Affine) *P1Aggregate {
	if agg.v == nil {
		agg.v = new(P1)
		C.blst_p1_from_affine(agg.v, elmt)
	} else {
		C.blst_p1_add_or_double_affine(agg.v, agg.v, elmt)
	}
	return agg
}

func (agg *P1Aggregate) ToAffine() *P1Affine {
	if agg.v == nil {
		return new(P1Affine)
	}
	return agg.v.ToAffine()
}

func (agg *P1Aggregate) aggregate(getter aggGetterP1, n int) bool {
	if n == 0 {
		return true
	}
	// operations are considered short enough for not to care about
	// keeping one core free...
	numThreads := runtime.GOMAXPROCS(0)
	if numThreads > n {
		numThreads = n
	}

	valid := int32(1)
	type result struct {
		agg   *P1
		empty bool
	}
	msgs := make(chan result, numThreads)
	curItem := uint32(0)
	for tid := 0; tid < numThreads; tid++ {
		go func() {
			first := true
			var agg P1
			var temp P1Affine
			for atomic.LoadInt32(&valid) > 0 {
				// Get a work item
				work := atomic.AddUint32(&curItem, 1) - 1
				if work >= uint32(n) {
					break
				}

				// Signature validate
				curElmt := getter(work, &temp)
				if curElmt == nil {
					atomic.StoreInt32(&valid, 0)
					break
				}
				if first {
					C.blst_p1_from_affine(&agg, curElmt)
					first = false
				} else {
					C.blst_p1_add_or_double_affine(&agg, &agg, curElmt)
				}
				// application might have some async work to do
				runtime.Gosched()
			}
			if first {
				msgs <- result{nil, true}
			} else if atomic.LoadInt32(&valid) > 0 {
				msgs <- result{&agg, false}
			} else {
				msgs <- result{nil, false}
			}
		}()
	}

	// Accumulate the thread results
	first := agg.v == nil
	validLocal := true
	for i := 0; i < numThreads; i++ {
		msg := <-msgs
		if !validLocal || msg.empty {
			// do nothing
		} else if msg.agg == nil {
			validLocal = false
			// This should be unnecessary but seems safer
			atomic.StoreInt32(&valid, 0)
		} else {
			if first {
				agg.v = msg.agg
				first = false
			} else {
				C.blst_p1_add(agg.v, agg.v, msg.agg)
			}
		}
	}
	if atomic.LoadInt32(&valid) == 0 {
		agg.v = nil
		return false
	}
	return true
}

//
// Serialization/Deserialization.
//

// P1 Serdes
func (p1 *P1Affine) Serialize() []byte {
	var out [BLST_P1_SERIALIZE_BYTES]byte
	C.blst_p1_affine_serialize((*C.byte)(&out[0]), p1)
	return out[:]
}

func (p1 *P1Affine) Deserialize(in []byte) *P1Affine {
	if len(in) != BLST_P1_SERIALIZE_BYTES {
		return nil
	}
	if C.blst_p1_deserialize(p1,
		(*C.byte)(&in[0])) != C.BLST_SUCCESS {
		return nil
	}
	// CLEANUP!!
	// Check for infinities (eth spec)
	var zero P1Affine
	if p1.Equals(&zero) {
		return p1
	}
	// CLEANUP!!

	if !bool(C.blst_p1_affine_in_g1(p1)) {
		return nil
	}
	return p1
}
func (p1 *P1Affine) Compress() []byte {
	var out [BLST_P1_COMPRESS_BYTES]byte
	C.blst_p1_affine_compress((*C.byte)(&out[0]), p1)
	return out[:]
}

func (p1 *P1Affine) Uncompress(in []byte) *P1Affine {
	if len(in) != BLST_P1_COMPRESS_BYTES {
		return nil
	}
	if C.blst_p1_uncompress(p1,
		(*C.byte)(&in[0])) != C.BLST_SUCCESS {
		return nil
	}
	// CLEANUP!!
	// Check for infinities (eth spec)
	var zero P1Affine
	if p1.Equals(&zero) {
		return p1
	}
	// CLEANUP!!

	if !bool(C.blst_p1_affine_in_g1(p1)) {
		return nil
	}
	return p1
}

func (p1 *P1Affine) InG1() bool {
	return bool(C.blst_p1_affine_in_g1(p1))
}

func (dummy *P1Affine) BatchUncompress(in [][]byte) []*P1Affine {
	// Allocate space for all of the resulting points. Later we'll save pointers
	// and return those so that the result could be used in other functions,
	// such as MultipleAggregateVerify.
	n := len(in)
	points := make([]P1Affine, n)
	pointsPtrs := make([]*P1Affine, n)

	numCores := runtime.GOMAXPROCS(0)
	numThreads := maxProcs
	if numThreads > numCores {
		numThreads = numCores
	}
	if numThreads > n {
		numThreads = n
	}
	// Each thread will determine next message to process by atomically
	// incrementing curItem, process corresponding point, and
	// repeat until n is exceeded. Each thread will send a result (true for
	// success, false for failure) into the channel when complete.
	resCh := make(chan bool, numThreads)
	valid := int32(1)
	curItem := uint32(0)
	for tid := 0; tid < numThreads; tid++ {
		go func() {
			for atomic.LoadInt32(&valid) > 0 {
				// Get a work item
				work := atomic.AddUint32(&curItem, 1) - 1
				if work >= uint32(n) {
					break
				}
				if points[work].Uncompress(in[work]) == nil {
					atomic.StoreInt32(&valid, 0)
					break
				}
				pointsPtrs[work] = &points[work]
			}
			if atomic.LoadInt32(&valid) > 0 {
				resCh <- true
			} else {
				resCh <- false
			}
		}()
	}

	// Collect the threads
	result := true
	for i := 0; i < numThreads; i++ {
		if !<-resCh {
			result = false
		}
	}
	if atomic.LoadInt32(&valid) == 0 || result == false {
		return nil
	}
	return pointsPtrs
}

func (p1 *P1) Serialize() []byte {
	var out [BLST_P1_SERIALIZE_BYTES]byte
	C.blst_p1_serialize((*C.byte)(&out[0]), p1)
	return out[:]
}
func (p1 *P1) Compress() []byte {
	var out [BLST_P1_COMPRESS_BYTES]byte
	C.blst_p1_compress((*C.byte)(&out[0]), p1)
	return out[:]
}

//
// Affine
//

func (p *P1) ToAffine() *P1Affine {
	var pa P1Affine
	C.blst_p1_to_affine(&pa, p)
	return &pa
}

//
// Hash
//
func HashToG1(msg []byte, dst []byte,
	optional ...[]byte) *P1 { // aug
	var q P1

	// Handle zero length message
	var msgC *C.byte
	if len(msg) > 0 {
		msgC = (*C.byte)(&msg[0])
	}

	var dstC *C.byte
	if len(dst) > 0 {
		dstC = (*C.byte)(&dst[0])
	}

	var aug []byte
	var uaug *C.byte
	if len(optional) > 0 {
		aug = optional[0]
		if len(aug) > 0 {
			uaug = (*C.byte)(&aug[0])
		}
	}

	C.blst_hash_to_g1(&q, msgC, C.size_t(len(msg)),
		dstC, C.size_t(len(dst)),
		uaug, C.size_t(len(aug)))
	return &q
}

func EncodeToG1(msg []byte, dst []byte,
	optional ...[]byte) *P1 { // aug
	var q P1

	// Handle zero length message
	var msgC *C.byte
	if len(msg) > 0 {
		msgC = (*C.byte)(&msg[0])
	}

	var dstC *C.byte
	if len(dst) > 0 {
		dstC = (*C.byte)(&dst[0])
	}

	var aug []byte
	var uaug *C.byte
	if len(optional) > 0 {
		aug = optional[0]
		if len(aug) > 0 {
			uaug = (*C.byte)(&aug[0])
		}
	}

	C.blst_encode_to_g1(&q, msgC, C.size_t(len(msg)),
		dstC, C.size_t(len(dst)),
		uaug, C.size_t(len(aug)))
	return &q
}

//
// Serialization/Deserialization.
//

// P2 Serdes
func (p2 *P2Affine) Serialize() []byte {
	var out [BLST_P2_SERIALIZE_BYTES]byte
	C.blst_p2_affine_serialize((*C.byte)(&out[0]), p2)
	return out[:]
}

func (p2 *P2Affine) Deserialize(in []byte) *P2Affine {
	if len(in) != BLST_P2_SERIALIZE_BYTES {
		return nil
	}
	if C.blst_p2_deserialize(p2,
		(*C.byte)(&in[0])) != C.BLST_SUCCESS {
		return nil
	}
	// CLEANUP!!
	// Check for infinities (eth spec)
	var zero P2Affine
	if p2.Equals(&zero) {
		return p2
	}
	// CLEANUP!!

	if !bool(C.blst_p2_affine_in_g2(p2)) {
		return nil
	}
	return p2
}
func (p2 *P2Affine) Compress() []byte {
	var out [BLST_P2_COMPRESS_BYTES]byte
	C.blst_p2_affine_compress((*C.byte)(&out[0]), p2)
	return out[:]
}

func (p2 *P2Affine) Uncompress(in []byte) *P2Affine {
	if len(in) != BLST_P2_COMPRESS_BYTES {
		return nil
	}
	if C.blst_p2_uncompress(p2,
		(*C.byte)(&in[0])) != C.BLST_SUCCESS {
		return nil
	}
	// CLEANUP!!
	// Check for infinities (eth spec)
	var zero P2Affine
	if p2.Equals(&zero) {
		return p2
	}
	// CLEANUP!!

	if !bool(C.blst_p2_affine_in_g2(p2)) {
		return nil
	}
	return p2
}

func (p2 *P2Affine) InG2() bool {
	return bool(C.blst_p2_affine_in_g2(p2))
}

func (dummy *P2Affine) BatchUncompress(in [][]byte) []*P2Affine {
	// Allocate space for all of the resulting points. Later we'll save pointers
	// and return those so that the result could be used in other functions,
	// such as MultipleAggregateVerify.
	n := len(in)
	points := make([]P2Affine, n)
	pointsPtrs := make([]*P2Affine, n)

	numCores := runtime.GOMAXPROCS(0)
	numThreads := maxProcs
	if numThreads > numCores {
		numThreads = numCores
	}
	if numThreads > n {
		numThreads = n
	}
	// Each thread will determine next message to process by atomically
	// incrementing curItem, process corresponding point, and
	// repeat until n is exceeded. Each thread will send a result (true for
	// success, false for failure) into the channel when complete.
	resCh := make(chan bool, numThreads)
	valid := int32(1)
	curItem := uint32(0)
	for tid := 0; tid < numThreads; tid++ {
		go func() {
			for atomic.LoadInt32(&valid) > 0 {
				// Get a work item
				work := atomic.AddUint32(&curItem, 1) - 1
				if work >= uint32(n) {
					break
				}
				if points[work].Uncompress(in[work]) == nil {
					atomic.StoreInt32(&valid, 0)
					break
				}
				pointsPtrs[work] = &points[work]
			}
			if atomic.LoadInt32(&valid) > 0 {
				resCh <- true
			} else {
				resCh <- false
			}
		}()
	}

	// Collect the threads
	result := true
	for i := 0; i < numThreads; i++ {
		if !<-resCh {
			result = false
		}
	}
	if atomic.LoadInt32(&valid) == 0 || result == false {
		return nil
	}
	return pointsPtrs
}

func (p2 *P2) Serialize() []byte {
	var out [BLST_P2_SERIALIZE_BYTES]byte
	C.blst_p2_serialize((*C.byte)(&out[0]), p2)
	return out[:]
}
func (p2 *P2) Compress() []byte {
	var out [BLST_P2_COMPRESS_BYTES]byte
	C.blst_p2_compress((*C.byte)(&out[0]), p2)
	return out[:]
}

//
// Affine
//

func (p *P2) ToAffine() *P2Affine {
	var pa P2Affine
	C.blst_p2_to_affine(&pa, p)
	return &pa
}

//
// Hash
//
func HashToG2(msg []byte, dst []byte,
	optional ...[]byte) *P2 { // aug
	var q P2

	// Handle zero length message
	var msgC *C.byte
	if len(msg) > 0 {
		msgC = (*C.byte)(&msg[0])
	}

	var dstC *C.byte
	if len(dst) > 0 {
		dstC = (*C.byte)(&dst[0])
	}

	var aug []byte
	var uaug *C.byte
	if len(optional) > 0 {
		aug = optional[0]
		if len(aug) > 0 {
			uaug = (*C.byte)(&aug[0])
		}
	}

	C.blst_hash_to_g2(&q, msgC, C.size_t(len(msg)),
		dstC, C.size_t(len(dst)),
		uaug, C.size_t(len(aug)))
	return &q
}

func EncodeToG2(msg []byte, dst []byte,
	optional ...[]byte) *P2 { // aug
	var q P2

	// Handle zero length message
	var msgC *C.byte
	if len(msg) > 0 {
		msgC = (*C.byte)(&msg[0])
	}

	var dstC *C.byte
	if len(dst) > 0 {
		dstC = (*C.byte)(&dst[0])
	}

	var aug []byte
	var uaug *C.byte
	if len(optional) > 0 {
		aug = optional[0]
		if len(aug) > 0 {
			uaug = (*C.byte)(&aug[0])
		}
	}

	C.blst_encode_to_g2(&q, msgC, C.size_t(len(msg)),
		dstC, C.size_t(len(dst)),
		uaug, C.size_t(len(aug)))
	return &q
}

func parseOpts(optional ...interface{}) ([]byte, [][]byte, bool, bool) {
	var aug [][]byte     // For aggregate verify
	var augSingle []byte // For signing
	useHash := true      // hash (true), encode (false)

	for _, arg := range optional {
		switch v := arg.(type) {
		case []byte:
			augSingle = v
		case [][]byte:
			aug = v
		case bool:
			useHash = v
		default:
			return nil, nil, useHash, false
		}
	}
	return augSingle, aug, useHash, true
}

func bytesAllZero(s []byte) bool {
	for _, v := range s {
		if v != 0 {
			return false
		}
	}
	return true
}

//
// Serialization/Deserialization.
//

// Scalar serdes
func (s *Scalar) Serialize() []byte {
	var out [BLST_SCALAR_BYTES]byte
	C.blst_bendian_from_scalar((*C.byte)(&out[0]), s)
	return out[:]
}

func (s *Scalar) Deserialize(in []byte) *Scalar {
	if len(in) != BLST_SCALAR_BYTES {
		return nil
	}
	C.blst_scalar_from_bendian(s, (*C.byte)(&in[0]))
	if !C.blst_scalar_fr_check(s) {
		return nil
	}
	return s
}

func (s *Scalar) Valid() bool {
	return bool(C.blst_scalar_fr_check(s))
}

//
// LEndian
//

func (fr *Scalar) ToLEndian() []byte {
	var arr [BLST_SCALAR_BYTES]byte
	C.blst_lendian_from_scalar((*C.byte)(&arr[0]), fr)
	return arr[:]
}

func (fp *Fp) ToLEndian() []byte {
	var arr [BLST_FP_BYTES]byte
	C.blst_lendian_from_fp((*C.byte)(&arr[0]), fp)
	return arr[:]
}

func (fr *Scalar) FromLEndian(arr []byte) *Scalar {
	if len(arr) != BLST_SCALAR_BYTES {
		return nil
	}
	C.blst_scalar_from_lendian(fr, (*C.byte)(&arr[0]))
	return fr
}

func (fp *Fp) FromLEndian(arr []byte) *Fp {
	if len(arr) != BLST_FP_BYTES {
		return nil
	}
	C.blst_fp_from_lendian(fp, (*C.byte)(&arr[0]))
	return fp
}

//
// BEndian
//

func (fr *Scalar) ToBEndian() []byte {
	var arr [BLST_SCALAR_BYTES]byte
	C.blst_bendian_from_scalar((*C.byte)(&arr[0]), fr)
	return arr[:]
}

func (fp *Fp) ToBEndian() []byte {
	var arr [BLST_FP_BYTES]byte
	C.blst_bendian_from_fp((*C.byte)(&arr[0]), fp)
	return arr[:]
}

func (fr *Scalar) FromBEndian(arr []byte) *Scalar {
	if len(arr) != BLST_SCALAR_BYTES {
		return nil
	}
	C.blst_scalar_from_bendian(fr, (*C.byte)(&arr[0]))
	return fr
}

func (fp *Fp) FromBEndian(arr []byte) *Fp {
	if len(arr) != BLST_FP_BYTES {
		return nil
	}
	C.blst_fp_from_bendian(fp, (*C.byte)(&arr[0]))
	return fp
}

//
// Printing
//

func PrintBytes(val []byte, name string) {
	fmt.Printf("%s = %02x\n", name, val)
}

func (s *Scalar) Print(name string) {
	arr := s.ToBEndian()
	PrintBytes(arr[:], name)
}

func (p *P1Affine) Print(name string) {
	fmt.Printf("%s:\n", name)
	arr := p.x.ToBEndian()
	PrintBytes(arr, "  x")
	arr = p.y.ToBEndian()
	PrintBytes(arr, "  y")
}

func (p *P1) Print(name string) {
	fmt.Printf("%s:\n", name)
	aff := p.ToAffine()
	aff.Print(name)
}

func (f *Fp2) Print(name string) {
	fmt.Printf("%s:\n", name)
	arr := f.fp[0].ToBEndian()
	PrintBytes(arr, "    0")
	arr = f.fp[1].ToBEndian()
	PrintBytes(arr, "    1")
}

func (p *P2Affine) Print(name string) {
	fmt.Printf("%s:\n", name)
	p.x.Print("  x")
	p.y.Print("  y")
}

func (p *P2) Print(name string) {
	fmt.Printf("%s:\n", name)
	aff := p.ToAffine()
	aff.Print(name)
}

//
// Equality
//

func (s1 *Scalar) Equals(s2 *Scalar) bool {
	return *s1 == *s2
}

func (e1 *Fp) Equals(e2 *Fp) bool {
	return *e1 == *e2
}

func (e1 *Fp2) Equals(e2 *Fp2) bool {
	return *e1 == *e2
}

func (e1 *P1Affine) Equals(e2 *P1Affine) bool {
	return bool(C.blst_p1_affine_is_equal(e1, e2))
}

func (e1 *P1) Equals(e2 *P1) bool {
	return bool(C.blst_p1_is_equal(e1, e2))
}

func (e1 *P2Affine) Equals(e2 *P2Affine) bool {
	return bool(C.blst_p2_affine_is_equal(e1, e2))
}

func (e1 *P2) Equals(e2 *P2) bool {
	return bool(C.blst_p2_is_equal(e1, e2))
}
